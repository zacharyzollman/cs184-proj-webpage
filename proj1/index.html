<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>My Website</title>
    <link rel="stylesheet" href="./style.css">
    <link rel="icon" href="./favicon.ico" type="image/x-icon">
  </head>
  <body>
    <main>
		<h1 class="center">Project 1: Rasterizer</h1>
		<p class="center">Abdul Ali Khan, Zachary Zollman</p>

		<h2 class="center">Task 1: Drawing Single-Color Triangles</h2>

    To rasterize a triangle, we first find the bounding box of the triangle by calculating the minimum and maximum x and y values of the three vertices. Then we iterate through each pixel in the bounding box and perform a three-line test to check if the pixel is inside the triangle. If the pixel is inside the triangle, we fill the pixel with the specified color.

    <br></br>
    The three-line test involves calculating the signed areas of three sub-triangles formed by the pixel and two vertices of the triangle. If the signed areas have the same sign, then the pixel is inside the triangle. We also add a half-pixel offset to the coordinates when filling the pixel to ensure that the pixel is correctly centered within the bounding box. This is the basic approach to triangle rasterization without supersampling.

    <code>
      <br>
      // TODO: Task 1: Implement basic triangle rasterization here, no supersampling<br>
      <br>
      
   // find the bounding box of the triangle<br>
   int minX = min(x0, min(x1, x2));<br>
   int maxX = max(x0, max(x1, x2));<br>
   int minY = min(y0, min(y1, y2));<br>
   int maxY = max(y0, max(y1, y2));<br>


   // iterate through the bounding box<br>
   for (int x = minX; x <= maxX; x++)<br>
   {<br>
     for (int y = minY; y <= maxY; y++)<br>
     {<br>


       //three line test to see if the point is inside the triangle<br>
       float d1 = (x - x1) * (y0 - y1) - (x0 - x1) * (y - y1);<br>
       float d2 = (x - x2) * (y1 - y2) - (x1 - x2) * (y - y2);<br>
       float d3 = (x - x0) * (y2 - y0) - (x2 - x0) * (y - y0);<br>
      
       // if the point is inside the triangle, fill the pixel<br>
       if ((d1 >= 0 && d2 >= 0 && d3 >= 0) || (d1 <= 0 && d2 <= 0 && d3 <= 0))<br>
       {<br>
         fill_pixel(x + 0.5, y + 0.5, color);<br>
       }<br>
     }<br>
   }<br>
    </code>

    The given algorithm uses a bounding box to define the potential area of the triangle and iterates through each pixel within the bounding box to determine whether it is inside or outside of the triangle. As such, it covers every pixel within the bounding box, and therefore, it can't miss any pixels inside the triangle.
Therefore, the given algorithm is no worse than one that checks each sample within the bounding box of the triangle, and it provides a reasonable trade-off between computational efficiency and accuracy.
<br><br>
    <img src="task1.png" width="700">


		<h2 class="center">Task 2: Antialiasing by Supersampling</h2>

    Supersampling involves sampling your model multiple times per pixel, rather than just once per pixel. This is useful because it can reduce undesired behaviors that arise from sampling only once per sample, such as jaggies. By sampling multiple times, we can select a more representative pixel color. In particular, on edges, we can average the triangle color with the background/surrounding color. Thus, there isn’t a triangle present/triangle absent binary, but rather a gradual transition between the triangle’s color and its surroundings.<br>
    <br><br>
    In order to antialias our triangles, we increased the size of our sample buffer so that we could store one color per sample. In order to achieve this, we modified the <code>sample_buffer.resize()</code> calls in <code>set_sample_rate</code> and <code>set_framebuffer_target</code> to set the size to <code>width * height * sample_rate</code>. We also modified the <code>rasterize_triangle</code> function to be able to sample multiple points within the given pixel. The samples are evenly spaced in a sort of mini-grid within the grid of pixels. As we move through the grids using for loops, we set the color in the sample buffer to be the triangle color if it is within the triangle. We modified <code>resolve_to_framebuffer</code> so that it could take in multiple sample colors from the sample buffer to determine a single pixel color. Specifically, we averaged the color values. This involved summing the RGB values for each color and dividing by the number of colors. We implemented supersampling for triangles, but we still wanted lines and points to render appropriately, so we modified <code>fill_pixel</code> to fill all corresponding samples in the sample buffer with the desired color. That way, when the corresponding samples were averaged to determine the color for the pixel, they averaged to the desired color.

    <br><br>
    <img src="task1.png" width="700">
    <img src="task2-sr4.png" width="700">
    <img src="task2-sr9.png" width="700">
    <img src="task2-sr16.png" width="700">


		<h2 class="center">Task 3: Transforms</h2>

    <img src="task3.png" width="700">
    <br><br>
    The cubeman is mid-somersault, trying to get into a handstand to then swing his legs around underneath himself. I have changed the body color by adding blue tiles to give him more motion.

		<h2 class="center">Task 4: Barycentric coordinates</h2>
    <img src="barycentric-interpolation-triangle.png" width="700">
    
    <br><br>
    Barycentric coordinates are a way to represent a point inside a triangle as a linear combination of the triangle's vertices. The coordinates are determined by computing the ratios of the areas of three smaller triangles formed by the point and each of the triangle's edges, to the area of the entire triangle. These ratios represent the weights assigned to each vertex to calculate the position of the point. 
    <br><br>
    Barycentric coordinates are simply a set of numbers that describe a linear combination of vertices of a given triangle.
    <br><br>

    
    <p>Given triangle △ABC, if P=(α,β,γ), where α+β+γ=1, and A, B, C each has an associated value, then P=αA+βB+γC</p>
    <p>We know that the coordinates of point P can be expressed as a linear combination of the coordinates of points A, B, and C. That is,</p>
    <p>P = αA + βB + γC</p>
    <p>where α, β, and γ are constants that represent the weights of each point in the linear combination.</p>
    <p>Since α+β+γ=1, we can rewrite the equation as:</p>
    <p>P = (α/1)A + (β/1)B + (γ/1)C</p>
    <p>This can be interpreted as a weighted average of the values of A, B, and C, where the weights are α, β, and γ respectively. Thus, P is the center of gravity of the triangle.</p>
    <p>Therefore, we have proved that if P=(α,β,γ), where α+β+γ=1, and A, B, C each has an associated value, then P=αA+βB+γC.</p>

    <br><br>

    <img src="task4.png" width="700">

		<h2 class="center">Task 5: "Pixel sampling" for texture mappings</h2>

    Pixel sampling involves sampling colors on a texture to determine which color gets mapped from the texture onto a shape that actually gets rendered. Our code iterates through locations on a rendered triangle and calculates their barycentric coordinates, and then passes those coordinates to a sampling function in texture.cpp using a struct called <code>SampleParams</code>. There are two different pixel sampling functions: nearest and bilinear. The first finds the nearest location on the texture map and returns its color, while bilinear performs a bilinear interpolation based on the four nearest values of the texture map. We can think of the texture map as a square grid with color values on the vertices; nearest sampling finds the nearest vertex, while bilinear finds the surrounding vertices (upper left, lower left, upper right, and lower right) and averages them based on how close they are to the coordinate we are sampling. Each function accesses colors on the texture map by calling <code>MipLevel::get_texel</code>
    <br><br>
    <img src="task5-p_nearest-1.png" width="700">
    <img src="task5-p_linear-1.png" width="700">
    <br><br>
    There is a clear difference between nearest pixel and bilinear sampling with 1 sample per pixel, which is that fine details of the image have more sudden and extreme variation in the nearest pixel version. For example, in the pixel inspector, we can see that the latitude and longitude lines on the globe are more jagged and discontinuous on the nearest pixel version. Looking at the nearest pixel image as a whole, we can see that some of the longitude lines disappear around the equator, and that the lines that are present have a more jagged appearance.
    <br><br>
    <img src="task5-p_nearest-16.png" width="700">
    <img src="task5-p_linear-16.png" width="700">
    <br><br>
    Both of these 16-sample-per-pixel images are smoother than their 1-sample-per-pixel counterparts. Unlike the smoothing in the bilinear image with 1 sample per pixel, this smoothness includes smoothness of the edges. In other words, for both of these images with more supersampling, the transition between the rendered world map image and the background is more gradual and less jagged. Between the two images, we can see that the nearest pixel sampling has again produced some discontinuities in the latitude and longitude lines, but they are less noticeable at 16 samples per pixel because they are smoothed out. The bilinear sampling does not have that issue to such a great extent. Out of all of the options, bilinear sampling at 16 samples per pixel is the smoothest, and nearest sampling at 1 sample per pixel is the most jagged.
    <br><br>
    Overall, it seems that bilinear sampling leads to smoother transitions between colors within rendered shapes than nearest sampling. Increasing the number of samples per pixel also leads to smoother transitions between colors within rendered shapes, and also between the shapes and the background. The difference between nearest and bilinear sampling is noticeable in the jaggedness or smoothness at boundaries between colors, so it is likely to be most noticeable when there are fine details in the image with high contrast in color. In the images discussed above, the latitude and longitude lines, which were relatively thin, were finer details on the world map. The white lines stood out prominently against the blue waters of the world map. This makes sense because nearest sampling only results in colors that are in the texture map, whereas bilinear sampling can interpolate based on colors that are in the map. On a boundary between multiple colors, nearest sampling will choose the nearest color value on the map, whereas bilinear will interpolate the multiple colors and produce a blend, resulting in smoother transitions.


		<h2 class="center">Task 6: "Level sampling" with mipmaps for texture mapping</h2>

    Level sampling involves pre-computing different levels of resolution of an image and then sampling from appropriate levels, rather than always sampling from the highest-quality image. To implement it, we fill our <code>SampleParams</code> struct with information relevant to sampling, including the level sampling method and the pixel sampling method. We also take the coordinates of the sample point, the point one unit above the sample point, and the point one unit to the right of the sample point, convert them to barycentric coordinates, and store them in the struct. We then pass this struct to our sampling function, <code>Texture::sample</code>. The behavior of this function depends on the level sampling method. For zeroth level sampling, we sample at the zeroth level. For nearest level sampling, we calculate the nearest level to the level that we calculated to be appropriate and sample at that level. For linear level sampling, we sample at the two nearest levels and interpolate between them based on how close they are to the level that we calculated to be appropriate. To calculate which level is appropriate, we use another function called <code>Texture::get_level</code>. In this function, we calculate the difference vectors between the sample’s barycentric coordinate and the sample’s barycentric coordinate with the 1-unit x-offset and y-offset. We then scale the difference in the x-values by the width of the texture and the y-values by the height of the texture. We then select the larger norm of these two vectors, and pass this value into the logarithm function with base 2. If the value is not within the range of possible values for levels, we clamp it to be within this range.
    <br><br>
    Switching from nearest pixel sampling to linear pixel sampling decreases speed and increases antialiasing power. Storing pre-computed lower-resolution levels in a mipmap increases memory usage, but using them can increase antialiasing power and they can be faster than supersampling. Relative to nearest level sampling, bilinear sampling is slower but increases antialiasing power. Supersampling increases antialiasing power substantially, but decreases speed and generally increases memory usage since more values are stored per rendered pixel.
    <br><br>
    <img src="task6-l_zero-p_nearest.png" width="700">
    <img src="task6-l_zero-p_linear.png" width="700">
    <img src="task6-l_nearest-p_nearest.png" width="700">
    <img src="task6-l_nearest-p_linear.png" width="700">
    <br><br>
    We can see in these images that the most jagged option of the ones specified is <code>L_ZERO</code> and <code>P_NEAREST</code>, and the smoothest option is <code>L_NEAREST</code> and <code>P_LINEAR</code>. The difference between <code>L_ZERO</code> and <code>L_NEAREST</code> appears to be more dramatic than the difference between <code>P_NEAREST</code> and <code>P_LINEAR</code> for this rendered image.
    <br><br>
    <h2 class="center">Link</h2>
    Link to write-up: <a href="https://zacharyzollman.github.io/cs184-proj-webpage/proj1/index.html">https://zacharyzollman.github.io/cs184-proj-webpage/proj1/index.html</a>
    </main>
	<script src="index.js"></script>
  </body>
</html>